\documentclass[11pt]{article}
\usepackage[a4paper,top=2cm,bottom=3cm,left=1.5cm,right=1.5cm]{geometry}
\usepackage{titling}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{thmtools}
\usepackage[shortlabels]{enumitem}
\usepackage{abstract}
\usepackage{hyperref}
\usepackage{cleveref}

\title{Set Theory}
\date{Spring 2021}

% bold math
\makeatletter
\g@addto@macro\bfseries{\boldmath}
\makeatother

% remove abstract title
\renewcommand{\abstractname}{}
\renewcommand{\absnamepos}{empty}

% style of links
\hypersetup{colorlinks,linkcolor=black}

% set theorem style
\declaretheoremstyle[
  spaceabove=6pt, spacebelow=6pt,
  headfont=\normalfont\bfseries,
  notefont=\normalfont\bfseries,
  bodyfont=\normalfont\upshape,
  postheadspace=0.5em
]{custom}

% set qed symbol
\renewcommand{\qedsymbol}{$\blacksquare$}

% types of theorems
\declaretheorem[style=custom,parent=section]{definition}
\declaretheorem[style=custom,sibling=definition]{example}
\declaretheorem[style=custom,sibling=definition]{axiom}
\declaretheorem[style=custom,sibling=definition,name=Axiom Schema]{axiomschema}
\declaretheorem[style=custom,sibling=definition]{proposition}
\declaretheorem[style=custom,sibling=definition]{theorem}
\declaretheorem[style=custom,sibling=definition]{corollary}

% use bold fonts to emphasize
\DeclareTextFontCommand{\emph}{\bfseries}

% math operators
\DeclareMathOperator{\pow}{Pow}
\DeclareMathOperator{\dom}{Dom}
\DeclareMathOperator{\ran}{Ran}
\DeclareMathOperator{\suc}{succ}
\DeclareMathOperator{\prd}{pred}

\newcommand{\id}{\mathrm{id}}

\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}

\begin{document}

% title
\begin{center}
  \LARGE \bfseries \thetitle, \thedate
\end{center}

\begin{abstract}
  This note is taken for the course "Set Theory", which is instructed by Hsueh-I Lu in Spring 2021.
\end{abstract}

\tableofcontents

\section{February 23, 2021}
\subsection{Course Introduction}
\begin{itemize}
  \item Scoring: Midterm exam ($50\%$) and final exam ($50\%$).
  \item References:
  \begin{itemize}
    \item \textsl{Set Theory: A First Course}, by Daniel Cunningham (2016).
    \item \textsl{Set Theory}, by Thomas Jech (2006).
    \item \textsl{Set Theory: An Introduction to Independence Proofs}, by Kenneth Kunen (1983).
    \item \textsl{Elements of Set Theory}, by Herbert Enderton (1977).
  \end{itemize}
\end{itemize}

\subsection{History}
\begin{itemize}
  \item In 1874, it was proved by Georg Cantor that there is no one-to-one correspondence between the set of natural numbers and the set of real numbers.
  Following that proof, the theory of ordinal and cardinal numbers was developed.
  \item In 1908, the first axiomatization of set theory was presented by Ernst Zermelo.
  However, the existence of some infinite sets cannot be proved in this theory.
  \item In 1930, with revisions from Abraham Fraenkel, the axiomatization of Zermelo--Fraenkel set theory was presented, which is currently regarded as the most common foundation for mathematics.
\end{itemize}

\subsection{Motivation}
A \emph{set} is a collection of distinct elements.
One can define a set either by enumerating the elements of a set, or by describing the rules that a set should satisfy.
However, if any properties are allowed to define a set, then one can construct a set which leads to a paradox.
Following are some examples.

\begin{itemize}
  \item Russell's paradox: Suppose that $R = \{S: S \notin S\}$. Then $R \in R$ if and only if $R \notin R$.
  \item Berry's paradox: Suppose that $B$ is the set that contains exactly the smallest positive integer $b$ that is not definable in under sixty letters. Then $b \in B$ if and only if $b \notin B$.
\end{itemize}
%
In order to avoid paradoxes, we need axiomatic set theory as a foundation for mathematics.

\begin{itemize}
  \item The Zermelo--Fraenkel set theory with the axiom of choice included is called \emph{ZFC}.
  \item If the axiom of choice is excluded, then the theory is called \emph{ZF}.
\end{itemize}
%
In ZFC, all sets lie on an infinite hierarchy, which is called the von Neumann universe.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \clip (-7,0) rectangle (7,4.5);
    \draw (0,0) -- (-3,4) (0,0) -- (3,4);
    \draw (-0.45,0.6) -- (0.45,0.6);
    \draw (-0.9,1.2) -- (0.9,1.2);
    \draw (-1.35,1.8) -- (1.35,1.8);
    \draw (-1.8,2.4) -- (1.8,2.4);
    \draw (-2.25,3) -- (2.25,3);
    \draw (-2.7,3.6) -- (2.7,3.6);
    \node[anchor=west] at (0.5,0.3) {$V_0 = \varnothing$};
    \node[anchor=west] at (0.95,0.9) {$V_1 = V_0 \cup \pow(V_0)$};
    \node[anchor=west] at (1.4,1.5) {$V_2 = V_1 \cup \pow(V_1)$};
    \node at (0,2.2) {$\vdots$};
    \node[anchor=west] at (2.3,2.7) {$V_\omega = \bigcup_{\alpha \in \omega} V_\alpha$};
    \node[anchor=west] at (2.75,3.3) {$V_{\omega+1} = V_\omega \cup \pow(V_\omega)$};
    \node at (0,4) {$\vdots$};
  \end{tikzpicture}
  \caption{The von Neumann universe.}
\end{figure}

\section{March 2, 2021}
\subsection{Logic}
One can write first-order logic formulas with only the four symbols $\neg$, $\wedge$, $\forall$ and $\in$, and it is convenient to adopt the following abbreviations.
\begin{align*}
  \varphi \vee \psi \quad &\equiv \quad \neg (\neg \varphi \wedge \neg \psi), \\
  \varphi \rightarrow \psi \quad &\equiv \quad \neg \varphi \vee \psi, \\
  \varphi \leftrightarrow \psi \quad &\equiv \quad (\varphi \rightarrow \psi) \wedge (\psi \rightarrow \varphi), \\
  \exists x \varphi \quad &\equiv \quad \neg \forall x \neg \varphi, \\
  x = y \quad &\equiv \quad \forall w (w \in x \leftrightarrow w \in y) \wedge \forall z (x \in z \leftrightarrow y \in z), \\
  x \subseteq y \quad &\equiv \quad \forall w (w \in x \rightarrow w \in y).
\end{align*}
For any relation symbol $\sim$ (e.g., $\in$, $=$, $\subseteq$ are relation symbols), let
\begin{equation*}
  x \not\sim y \quad \equiv \quad \neg (x \sim y).
\end{equation*}

\subsection{Equality}
\begin{axiom}[Extensionality]
  Two sets are equal if they contain exactly the same elements.
  \begin{equation*}
    \forall x \forall y (\forall w (w \in x \leftrightarrow w \in y) \rightarrow x = y). 
  \end{equation*}
\end{axiom}

\subsection{The Empty Set}
\begin{axiom}[Empty Set]
  There exists a set that contains no members.
  \begin{equation*}
    \exists y \forall x (x \notin y).
  \end{equation*}
\end{axiom}

\begin{definition}
  Let $\varnothing$ denote the set that contains no members.
\end{definition}

\subsection{Pairing}
\begin{axiom}[Pairing]
  For any two sets $x$ and $y$, there is a set that contains exactly both $x$ and $y$.
  \begin{equation*}
    \forall x \forall y \exists z \forall w (w \in z \leftrightarrow (w = x \vee w = y)).
  \end{equation*}
\end{axiom}

\begin{definition}
  Let $\{x, y\}$ denote the set that contains exactly both $x$ and $y$.
  \begin{equation*}
    \forall x \forall y \forall w (w \in \{x, y\} \leftrightarrow (w = x \vee w = y)).
  \end{equation*}
  Also, let $\{x\} = \{x, x\}$ for any set $x$.
\end{definition}

\subsection{Unions}
\begin{axiom}[Union]
  For any set $y$, there exists a set that is the union of all members of $y$.
  \begin{equation*}
    \forall y \exists z \forall w (w \in z \leftrightarrow \exists x (w \in x \wedge x \in y)).
  \end{equation*}
\end{axiom}

\begin{definition}
  The union of all members of $y$ is denoted by $\bigcup y$.
\end{definition}

\begin{definition}
  For any sets $x$ and $y$, we define
  \begin{equation*}
    x \cup y = \bigcup \{x, y\}.
  \end{equation*}
\end{definition}

\subsection{Subsets}
\begin{axiomschema}[Separation]
  For any set $x$, there exists a set $y$ that contains the members of $x$ that satisfy $\varphi$, where $\varphi$ is a formula in which $y$ does not occur.
  That is, for any formula $\varphi$ whose free variables are among $v_1, v_2, \dots, v_k, w, x$, we have an axiom
  \begin{equation*}
    \forall v_1 \forall v_2 \cdots \forall v_k \forall x \exists y \forall w (w \in y \leftrightarrow (w \in x \wedge \varphi)).
  \end{equation*}
\end{axiomschema}

\begin{definition}
  For any set $x$, the set consisting of the members of $x$ that satisfy $\varphi$ is denoted by $\{w \in x: \varphi\}$.
\end{definition}

\begin{definition}
  For any sets $x$ and $y$, we define
  \begin{align*}
    x \cap y &= \{w \in x: w \in y\}, \\
    x \setminus y &= \{w \in x: w \notin y\}.
  \end{align*}
\end{definition}

\begin{definition}
  The intersection of all members of a nonempty set $y$, denoted by $\bigcap y$, is defined by
  \begin{equation*}
    \bigcap y = \Bigl\{w \in \bigcup y: \forall x (x \in y \to w \in x)\Bigr\}.
  \end{equation*}
\end{definition}

\subsection{Power Sets}
\begin{axiom}[Power Set]
  For any set $x$, there exists a set that contains all subsets of $x$.
  \begin{equation*}
    \forall x \exists y \forall z (z \in y \leftrightarrow z \subseteq x).
  \end{equation*}
\end{axiom}

\begin{definition}
  For any set $x$, the set containing all subsets of $x$ is called the \emph{power set} of $x$, denoted by $\pow(x)$.
\end{definition}

\section{March 9, 2021}
\subsection{Ordered Pairs}
\begin{definition}
  For any sets $x$ and $y$, let $(x, y) = \{\{x\}, \{x, y\}\}$.
\end{definition}

\begin{theorem}
  Let $P = (x, y)$.
  Then
  \begin{align*}
    x &= \bigcap \bigcap P, \\
    y &= \bigcap \Bigl\{w \in \bigcup P: w \notin \bigcap P \vee \bigcap P = \bigcup P\Bigr\}.
  \end{align*}
\end{theorem}
\begin{proof}
  Note that $\bigcap P = \{x\}$ and $\bigcup P = \{x, y\}$.
  It follows that $\bigcap \bigcap P = x$ holds, and we have $\bigcap P = \bigcup P$ if and only if $x = y$.
  Thus,
  \begin{equation*}
    \bigcap \Bigl\{w \in \bigcup P: w \notin \bigcap P \vee \bigcap P = \bigcup P\Bigr\}
    = \bigcap \{w \in \{x, y\}: w \neq x \vee x = y\}
    = \bigcap \{y\}
    = y.
    \qedhere
  \end{equation*}
\end{proof}

\begin{corollary}
  For any sets $u$, $v$, $x$ and $y$, we have $(u, v) = (x, y)$ if and only if $u = x$ and $v = y$.
\end{corollary}
\begin{proof}
  Clearly $u = x$ and $v = y$ imply
  \begin{equation*}
    (u, v)
    = \{\{u\}, \{u, v\}\}
    = \{\{x\}, \{x, y\}\}
    = (x, y).
  \end{equation*}
  If $(u, v) = (x, y)$, then
  \begin{equation*}
    u = \bigcap \bigcap (u, v) = \bigcap \bigcap (x, y) = x
  \end{equation*}
  and
  \begin{align*}
    v
    &= \bigcap \Bigl\{w \in \bigcup (u, v): w \notin \bigcap (u, v) \vee \bigcap (u, v) = \bigcup (u, v)\Bigr\} \\
    &= \bigcap \Bigl\{w \in \bigcup (x, y): w \notin \bigcap (x, y) \vee \bigcap (x, y) = \bigcup (x, y)\Bigr\} \\
    &= y.
    \qedhere
  \end{align*}
\end{proof}

\begin{definition}
  The \emph{Cartesian product} of two sets $X$ and $Y$, denoted by $X \times Y$, is defined by
  \begin{equation*}
    X \times Y = \{P \in \pow(\pow(X \cup Y)): \exists x \exists y (x \in X \wedge y \in Y \wedge (x, y) = P)\}.
  \end{equation*}
\end{definition}

\subsection{Relations}
\begin{definition}
  A \emph{relation} is a set $R$ such that each member of $R$ is an ordered pair.
\end{definition}

\begin{definition}
  For any relation $R$, the \emph{domain} and the \emph{range} of $R$, denoted by $\dom(R)$ and $\ran(R)$, respectively, are defined by
  \begin{align*}
    \dom(R) &= \Bigl\{x \in \bigcup \bigcup R: \exists y ((x, y) \in R) \Bigr\}, \\
    \ran(R) &= \Bigl\{y \in \bigcup \bigcup R: \exists x ((x, y) \in R) \Bigr\}.
  \end{align*}
\end{definition}

\begin{definition}
  For any relation $R$, the \emph{inverse} of $R$, denoted by $R^{-1}$, is defined by
  \begin{equation*}
    R^{-1} = \{P \in \ran(R) \times \dom(R): \exists x \exists y ((x, y) \in R \wedge (y, x) = P)\}.
  \end{equation*}
\end{definition}

\begin{definition}
  For any relations $R$ and $S$, the \emph{composition} of $R$ and $S$, denoted by $S \circ R$, is defined by
  \begin{equation*}
    S \circ R = \{P \in \dom(R) \times \ran(S): \exists x \exists y \exists z ((x, y) \in R \wedge (y, z) \in S \wedge (x, z) = P)\}.
  \end{equation*}
\end{definition}

\begin{definition}
  For any relation $R$ and any set $X$, the \emph{restriction} of $R$ to $X$, denoted by $R|_X$, is defined by
  \begin{equation*}
    R|_X = \{P \in R: \exists x \exists y (x \in X \wedge (x, y) = P\}.
  \end{equation*}
\end{definition}

\begin{definition}
  For any relation $R$ and any set $X$, the \emph{image} of $R$ under $X$, denoted by $R[X]$, is defined by
  \begin{equation*}
    R[X] = \ran(R|_X).
  \end{equation*}
\end{definition}

\subsection{Functions}
\begin{definition}
  A \emph{function} is a relation $f$ such that for any set $x \in \dom(f)$, there exists a unique set $y \in \ran(f)$ such that $(x, y) \in f$.
  If one writes $f: X \to Y$, then $f$ is a function with $\dom(f) = X$ and $\ran(f) \subseteq Y$, and $f$ is called a function from $X$ to $Y$.
  For any function $f: X \to Y$ and any $x \in X$, let $f(x)$ denote the unique member of $Y$ with $(x, f(x)) \in f$.
\end{definition}

\begin{definition}
  Let $X$ and $Y$ be sets.
  \begin{itemize}
    \item An \emph{injection} from $X$ to $Y$ is a function $f: X \to Y$ such that $f^{-1}$ is also a function.
    \item A \emph{surjection} from $X$ to $Y$ is a function $f: X \to Y$ such that $\ran(f) = Y$.
    \item A \emph{bijection} from $X$ to $Y$ is a function $f: X \to Y$ that is both an injection and a surjection from $X$ to $Y$.
  \end{itemize}
\end{definition}

\subsection{The Axiom of Choice}
\begin{axiom}[Choice]
  For any relation $R$, there exists a function $f \subseteq R$ with $\dom(f) = \dom(R)$.
\end{axiom}

\begin{theorem}
  Let $f: X \to Y$ be a function with $X \neq \varnothing$.
  Then there exists a function $g: Y \to X$ such that $g \circ f = \id_X$ if and only if $f$ is an injection from $X$ to $Y$.
\end{theorem}
\begin{proof}
  First suppose that $g: Y \to X$ is a function such that $g \circ f = \id_X$.
  For any $y \in Y$, let $x, x' \in X$ such that $(y, x), (y, x') \in f^{-1}$.
  Then we have
  \begin{equation*}
    x = (g \circ f)(x) = g(f(x)) = g(y) = g(f(x')) = (g \circ f)(x') = x'.
  \end{equation*}
  Thus, $f^{-1}$ is a function, implying that $f$ is an injection from $X$ to $Y$.
  \par Now suppose that $f$ is an injection from $X$ to $Y$, and let $x^\star$ be an arbitrary member of $X$.
  Define
  \begin{equation*}
    g = f^{-1} \cup ((Y \setminus \ran(f)) \times \{x^\star\}).
  \end{equation*}
  Note that
  \begin{itemize}
    \item $f^{-1}$ is a function from $\ran(f)$ to $X$, and
    \item $(Y \setminus \ran(f)) \times \{x^\star\}$ is a function from $Y \setminus \ran(f)$ to $X$.
  \end{itemize}
  Thus, $g$ is a function from $Y$ to $X$.
  We have $g \circ f = \id_X$ since
  \begin{equation*}
    (g \circ f)(x) = g(f(x)) = f^{-1}(f(x)) = x
  \end{equation*}
  holds for each $x \in X$.
\end{proof}

\begin{theorem}
  Let $f: X \to Y$ be a function with $X \neq \varnothing$.
  Then there exists a function $g: Y \to X$ such that $f \circ g = \id_Y$ if and only if $f$ is a surjection from $X$ to $Y$.
\end{theorem}
\begin{proof}
  First suppose that $g: Y \to X$ is a function such that $f \circ g = \id_Y$.
  For any $y \in Y$, we have
  \begin{equation*}
    y = (f \circ g)(y) = f(g(y)).
  \end{equation*}
  Thus, $f$ is a surjection from $X$ to $Y$.
  \par Now suppose that $f$ is a surjection from $X$ to $Y$.
  Then $f^{-1} \subseteq Y \times X$ is a relation.
  By the axiom of choice, there exists a function $g: Y \to X$ with $g \subseteq f^{-1}$.
  For any $y \in Y$, since $(y, g(y)) \in g \subseteq f^{-1}$, we have $(g(y), y) \in f$, implying $(f \circ g)(y) = f(g(y)) = y$.
  Thus, $f \circ g = \id_Y$.
\end{proof}

\section{March 16, 2021}
\subsection{Inductive Sets}
\begin{definition}
  Let $S$ be a set.
  The \emph{successor} of $S$, denoted by $\suc(S)$, is defined by $\suc(S) = S \cup \{S\}$.
\end{definition}

\begin{example}
  We have
  \begin{align*}
    \suc(\varnothing) &= \{\varnothing\}, \\
    \suc(\{\varnothing\}) &= \{\varnothing, \{\varnothing\}\}, \\
    \suc(\{\varnothing, \{\varnothing\}\}) &= \{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\}\}\}.
  \end{align*}
\end{example}

\begin{definition}
  A set $S$ is \emph{inductive} if $\varnothing \in S$, and $\suc(x) \in S$ for any $x \in S$.
\end{definition}

\begin{axiom}[Infinity]
  There exists an inductive set.
\end{axiom}

\begin{definition}
  Let $\omega$ denote the set containing the sets that are members of all inductive sets.
\end{definition}

\subsection{Peano Systems}
\begin{definition}
  \label{def:peano}
  Let $N$ be a set, let $s: N \to N$ be a function, and let $e \in N$.
  We say that $(N, s, e)$ is a \emph{Peano system} if the following conditions hold.
  \begin{enumerate}[(i)]
    \item For any $n \in N$, $s(n) \neq e$.
    \item For any $m, n \in N$, if $s(m) = s(n)$, then $m = n$.
    \item For any $M \subseteq N$, if $e \in N$, and $s(n) \in M$ holds for each $n \in M$, then $M = N$.
  \end{enumerate}
\end{definition}

\begin{theorem}[Induction Principle]
  \label{thm:induction}
  Let $I \subseteq \omega$.
  If $I$ is inductive, then $I = \omega$.
\end{theorem}
\begin{proof}
  Since $\omega$ is included in each inductive set, we have $\omega \subseteq I$.
  Thus $I = \omega$.
\end{proof}

\begin{proposition}
  For each nonempty $n \in \omega$, there exists $m \in \omega$ such that $\suc(m) = n$.
\end{proposition}
\begin{proof}
  Let $I$ be the subset of $\omega$ containing the sets $n$ such that either $n = \varnothing$ or $n = \suc(m)$ for some $m \in \omega$.
  Clearly $\varnothing \in I$.
  If $n \in I$, then we have $\suc(n) \in I$.
  Thus, $I$ is inductive, implying that $I = \omega$.
  This completes the proof.
\end{proof}

\section{March 23, 2021}
\subsection{Transitive Sets}
\begin{definition}
  A set $T$ is \emph{transitive} if $\bigcup T \subseteq T$.
\end{definition}

\begin{example}
  $\varnothing$, $\{\varnothing\}$, $\{\varnothing, \{\varnothing\}\}$, $\{\varnothing, \{\varnothing\}, \{\{\varnothing\}\}\}$, $\{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\}\}\}$ and $\{\varnothing, \{\varnothing\}, \{\{\varnothing\}\}, \{\varnothing, \{\varnothing\}\}\}$ are transitive sets.
\end{example}

\begin{theorem}
  The following statements hold.
  \begin{enumerate}[(a)]
    \item Each member of $\omega$ is transitive.
    \item $\omega$ is transitive.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item We show that $I = \{n \in \omega: \bigcup n \subseteq n\}$ is inductive.
    Since $\bigcup \varnothing \subseteq \varnothing$, we have $\varnothing \in I$.
    For each $n \in I$, we have $\bigcup n \subseteq n$, implying
    \begin{equation*}
      \bigcup \suc(n) = \bigcup (n \cup \{n\}) = \bigcup n \cup \bigcup \{n\} \subseteq n \cup \{n\} = \suc(n),
    \end{equation*}
    and thus $\suc(n) \in I$.
    Thus $I$ is inductive, completing the proof.
    \item First we show that $I = \{n \in \omega: n \subseteq \omega\}$ is inductive.
    Clearly $\varnothing \in I$.
    For each $n \in I$, we have $n \subseteq \omega$, and thus $\suc(n) = n \cup \{n\} \subseteq \omega$, implying $\suc(n) \in I$.
    Hence, $I$ is inductive, i.e., $n \subseteq \omega$ for each $n \in \omega$.
    \par Now we show that $\omega$ is transitive.
    For each $n \in \bigcup \omega$, there exists $m \in \omega$ such that $n \in m$.
    Then we have $m \subseteq \omega$, implying $n \in \omega$.
    Thus, $\bigcup \omega \subseteq \omega$, i.e., $\omega$ is transitive.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{theorem}
  \label{thm:predecessor}
  The following statements hold.
  \begin{enumerate}[(a)]
    \item For any $n \in \omega$, $\bigcup \suc(n) = n$.
    \item For any $m, n \in \omega$, $\suc(m) = \suc(n)$ implies $m = n$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Since $n$ is transitive, we have
    \begin{equation*}
      \bigcup \suc(n) = \bigcup (n \cup \{n\}) = \bigcup n \cup n = n.
    \end{equation*}
    \item If $\suc(m) = \suc(n)$, then $m = \bigcup \suc(m) = \bigcup \suc(n) = n$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{definition}
  For each nonempty $n \in \omega$, the \emph{predecessor} of $n$, denoted by $\prd(n)$, is defined by $\prd(n) = \bigcup n$.
\end{definition}

\begin{theorem}
  $(\omega, \sigma, \varnothing)$ is a Peano system, where $\sigma: \omega \to \omega$ is defined by $\sigma(n) = \suc(n)$ for each $n \in \omega$.
\end{theorem}
\begin{proof}
  Immediate from \Cref{thm:induction} and \Cref{thm:predecessor} (b).
\end{proof}

\subsection{Recursion}
\begin{theorem}[Recursion Theorem]
  \label{thm:recursion}
  For any set $N$, any function $s: N \to N$ and any $e \in N$, there exists a unique function $f: \omega \to N$ satisfying the following conditions.
  \begin{enumerate}[(i)]
    \item $f(\varnothing) = e$.
    \item $f(\suc(n)) = s(f(n))$ for all $n \in \omega$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  Let us call a function $h \subseteq \omega \times N$ \emph{good} if it satisfies the following conditions.
  \begin{enumerate}[(i)]
    \item If $\varnothing \in \dom(h)$, then $h(\varnothing) = e$.
    \item If $\suc(n) \in \dom(h)$ for some $n \in \omega$, then $n \in \dom(h)$ and $h(\suc(n)) = s(h(n))$.
  \end{enumerate}
  Let $f$ be the union of all good functions.
  It suffices to prove that $f$ is the unique good function such that $\dom(f) = \omega$.
  \par First, we show that $f$ is a function, i.e., $f[\{n\}]$ consists of at most one element for each $n \in \omega$.
  Clearly $f[\{\varnothing\}]$ contains at most one element since $f[\{\varnothing\}] \subseteq \{e\}$.
  Given that $f[\{n\}]$ contains at most one element for some $n \in \omega$, we show that $f[\{\suc(n)\}]$ also contains at most one element.
  If $(\suc(n), x) \in f$ and $(\suc(n), x') \in f$ for some $x, y \in N$, then $(\suc(n), x) \in h$ and $(\suc(n), x') \in h'$ hold for some good functions $h$ and $h'$, implying
  \begin{equation*}
    x = h(\suc(n)) = s(h(n)) = s(h'(n)) = h'(\suc(n)) = x'.
  \end{equation*}
  Thus, $f[\{\suc(n)\}]$ contains at most one element.
  It follows from induction principle that $f$ is a good.
  \par Next we show that $\dom(f) = \omega$, i.e., $\dom(f)$ is inductive.
  We have $\varnothing \in \dom(f)$ since $\{(\varnothing, e)\}$ is a good function.
  Now suppose that $n \in \dom(f)$, and we prove that $\suc(n) \in \dom(f)$.
  Since $n \in \dom(f)$, there exists a good function $h$ such that $n \in \dom(h)$.
  Obviously $\suc(n) \in \dom(h)$ implies $\suc(n) \in \dom(f)$.
  If $\suc(n) \notin \dom(h)$, then one can verify that
  \begin{equation*}
    h' = h \cup \{\suc(n), s(h(n))\}
  \end{equation*}
  is a good function, implying $\suc(n) \in \dom(f)$.
  Thus, $\dom(f) = \omega$.
  \par Now we show that $f$ is good.
  Clearly $f(\varnothing) = e$ since $\{(\varnothing, e)\}$ is good.
  For any $n \in \omega$, let $h \subseteq f$ be a good function such that $\suc(n) \in \dom(h)$, and we have
  \begin{equation*}
    f(\suc(n)) = h(\suc(n)) = s(h(n)) = s(f(n)).
  \end{equation*}
  Thus, $f$ is good.
  \par Finally, the uniqueness of $f$ follows from the fact that any good function $f'$ with $\dom(f') = \omega$ concides with $f$.
  This completes the proof.
\end{proof}

\begin{corollary}
  \label{thm:peano-isomorphism}
  Let $(N, s, e)$ be a Peano system.
  Then there exists a unique bijection $f$ from $\omega$ to $N$ satisfying the following conditions.
  \begin{enumerate}[(i)]
    \item $f(\varnothing) = e$.
    \item $f(\suc(n)) = s(f(n))$ for all $n \in \omega$.
  \end{enumerate}
\end{corollary}
\begin{proof}
  By recursion theorem, there exists a unique function $f: \omega \to N$ satisfying (i) and (ii).
  It suffices to prove that $f$ is a bijection from $\omega$ to $N$.
  \par First we show that $\ran(f) = N$.
  Clearly $e = f(\varnothing) \in \ran(f)$.
  If $x \in \ran(f)$, then $x = f(n)$ holds for some $n \in \omega$, implying $s(x) = s(f(n)) = f(\suc(n)) \in \ran(f)$.
  Thus, $\ran(f) = N$.
  \par Next we show that $f$ is injective.
  It suffices to show that
  \begin{equation*}
    I = \{n \in \omega: \forall m (m \in \omega \to (f(m) = f(n) \to m = n))\}
  \end{equation*}
  is inductive.
  For any $m \in \omega$, if $f(m) = f(\varnothing)$ and $m \neq \varnothing$, then
  \begin{equation*}
    e = f(\varnothing) = f(m) = f(\suc(\prd(m))) = s(f(\prd(m))),
  \end{equation*}
  contradition to the fact that $e \notin \ran(s)$.
  Thus $\varnothing \in I$.
  Now suppose that $n \in I$ holds for some $n \in \omega$, and we show that $\suc(n) \in I$.
  For any $m \in \omega$, if $f(m) = f(\suc(n))$, then $m \neq \varnothing$ since
  \begin{equation*}
    f(\suc(n)) = s(f(n)) \neq e = f(\varnothing).
  \end{equation*}
  Then since $s$ is injective and
  \begin{equation*}
    s(f(\prd(m))) = f(\suc(\prd(m))) = f(m) = f(\suc(n)) = s(f(n)),
  \end{equation*}
  we have $f(\prd(m)) = f(n)$, and it follows from $n \in I$ that $\prd(m) = n$, implying $m = \suc(\prd(m)) = \suc(n)$.
  Thus, $\suc(n) \in I$, completing the proof.
\end{proof}

\section{March 30, 2021}
From now on, we adopt the general representation for the successors of $\varnothing$, i.e., let $0 = \varnothing$, $1 = \suc(\varnothing)$, $2 = \suc(\suc(\varnothing))$, and so on.

\subsection{Addition}
\begin{definition}
  For each $m, n \in \omega$, we define
  \begin{equation*}
    m + n = A_m(n),
  \end{equation*}
  where $A_m: \omega \to \omega$ is the function such that $A_m(0) = m$, and $A_m(\suc(n)) = \suc(A_m(n))$ for each $n \in \omega$.
\end{definition}

\begin{proposition}
  For each $n \in \omega$, $\suc(n) = n + 1$.
\end{proposition}
\begin{proof}
  We have $\suc(n) = \suc(n + 0) = n + \suc(0) = n + 1$.
\end{proof}

\begin{proposition}
  The following statements hold for any $n \in \omega$.
  \begin{enumerate}[(a)]
    \item $0 + n = n$.
    \item $1 + n = n + 1$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Induction on $n$.
    Clearly $0 + 0 = 0$.
    Also, $0 + n = n$ implies $0 + (n + 1) = (0 + n) + 1 = n + 1$.
    \item Induction on $n$.
    Clearly $1 + 0 = 1 = 0 + 1$.
    Also, $1 + n = n + 1$ implies
    \begin{equation*}
      1 + (n + 1) = (1 + n) + 1 = (n + 1) + 1.
      \qedhere
    \end{equation*}
  \end{enumerate}
\end{proof}

\begin{theorem}
  The following statements hold for any $\ell, m, n \in \omega$.
  \begin{enumerate}[(a)]
    \item (Associativity) $(\ell + m) + n = \ell + (m + n)$.
    \item (Commutativity) $m + n = n + m$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Induction on $n$.
    Clearly
    \begin{equation*}
      (\ell + m) + 0
      = \ell + m
      = \ell + (m + 0).
    \end{equation*}
    Also, $(\ell + m) + n = \ell + (m + n)$ implies
    \begin{align*}
      (\ell + m) + (n + 1)
      &= ((\ell + m) + n) + 1 \\
      &= (\ell + (m + n)) + 1 \\
      &= \ell + ((m + n) + 1) \\
      &= \ell + (m + (n + 1)).
    \end{align*}
    \item Induction on $n$.
    Clearly $m + 0 = m = 0 + m$.
    Also, $m + n = n + m$ implies
    \begin{equation*}
      m + (n + 1)
      = (m + n) + 1
      = (n + m) + 1
      = n + (m + 1)
      = n + (1 + m)
      = (n + 1) + m.
      \qedhere
    \end{equation*}
  \end{enumerate}
\end{proof}

\subsection{Multiplication}
\begin{definition}
  For each $m, n \in \omega$, we define
  \begin{equation*}
    m \cdot n = M_m(n),
  \end{equation*}
  where $M_m: \omega \to \omega$ is the function such that $M_m(0) = 0$, and $M_m(\suc(n)) = m + M_m(n)$ for each $n \in \omega$.
\end{definition}

\begin{proposition}
  The following statements hold for any $n \in \omega$.
  \begin{enumerate}[(a)]
    \item $0 \cdot n = 0$.
    \item $1 \cdot n = n$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Induction on $n$.
    The inductive basis follows from $0 \cdot 0 = 0$.
    Assuming $0 \cdot n = 0$, the inductive step follows from
    \begin{equation*}
      0 \cdot (n + 1) = 0 + 0 \cdot n = 0 + 0 = 0.
    \end{equation*}
    \item Induction on $n$.
    The inductive basis follows from $1 \cdot 0 = 0$.
    Assuming $1 \cdot n = n$, the inductive step follows from
    \begin{equation*}
      1 \cdot (n + 1) = 1 + 1 \cdot n = 1 + n = n + 1.
      \qedhere
    \end{equation*}
  \end{enumerate}
\end{proof}

\begin{theorem}
  The following statements hold for any $\ell, m, n \in \omega$.
  \begin{enumerate}[(a)]
    \item (Right-distributivity) $(\ell + m) \cdot n = \ell \cdot n + m \cdot n$.
    \item (Commutativity) $m \cdot n = n \cdot m$.
    \item (Left-distributivity) $\ell \cdot (m + n) = \ell \cdot m + \ell \cdot n$.
    \item (Associativity) $(\ell \cdot m) \cdot n = \ell \cdot (m \cdot n)$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Induction on $n$.
    The inductive basis follows from
    \begin{equation*}
      (\ell + m) \cdot 0 = 0 = 0 + 0 = \ell \cdot 0 + m \cdot 0.
    \end{equation*}
    Assuming $(\ell + m) \cdot n = \ell \cdot n + m \cdot n$, the inductive step follows from
    \begin{align*}
      (\ell + m) \cdot (n + 1)
      &= (\ell + m) + (\ell + m) \cdot n \\
      &= (\ell + m) + (\ell \cdot n + m \cdot n) \\
      &= (\ell + \ell \cdot n) + (m + m \cdot n) \\
      &= \ell \cdot (n + 1) + m \cdot (n + 1).
    \end{align*}
    \item Induction on $n$.
    The inductive basis follows from $m \cdot 0 = 0 = 0 \cdot m$.
    Assuming $m \cdot n = n \cdot m$, the inductive step follows from
    \begin{equation*}
      m \cdot (n + 1)
      = m + m \cdot n
      = m \cdot n + m
      = n \cdot m + 1 \cdot m
      = (n + 1) \cdot m.
    \end{equation*}
    \item Straightforward from (a) and (b).
    \item Induction on $n$.
    The inductive basis follows from
    \begin{equation*}
      (\ell \cdot m) \cdot 0
      = 0
      = \ell \cdot 0
      = \ell \cdot (m \cdot 0).
    \end{equation*}
    Assuming $(\ell \cdot m) \cdot n = \ell \cdot (m \cdot n)$, the inductive step follows from
    \begin{align*}
      (\ell \cdot m) \cdot (n + 1)
      &= \ell \cdot m + (\ell \cdot m) \cdot n \\
      &= \ell \cdot m + \ell \cdot (m \cdot n) \\
      &= \ell \cdot (m + m \cdot n) \\
      &= \ell \cdot (m \cdot (n + 1)).
      \qedhere
    \end{align*}
  \end{enumerate}
\end{proof}

\subsection{Ordering}
\begin{definition}
  Let $X$ be a set.
  A relation $R \subseteq X \times X$ is said to \emph{linearly order} $X$ (i.e., $R$ is a \emph{linear ordering} over $X$) if the following statements (i) and (ii) hold.
  \begin{enumerate}[(i)]
    \item (Transitivity) For any $x, y, z \in R$, if $(x, y) \in R$ and $(y, z) \in R$, then $(x, z) \in R$.
    \item (Trichotomy) For any $x, y \in R$, exactly one of $x = y$, $(x, y) \in R$ and $(y, x) \in R$ holds.
  \end{enumerate}
  \par Also, a relation $R \subseteq X \times X$ is said to \emph{well-order} $X$ (i.e., $R$ is a \emph{well-ordering} over $X$) if $R$ linearly orders $X$ and the following statement (iii) holds.
  \begin{enumerate}[(i),resume]
    \item (Well-foundedness) For any nonempty subset $S$ of $X$, there exists an element $x \in S$ such that for each $y \in S$, either $x = y$ or $(x, y) \in R$ holds.
  \end{enumerate}
\end{definition}

\begin{definition}
  For all $m, n \in \omega$, we define
  \begin{align*}
    m < n \qquad &\iff \qquad m \in n, \\
    m > n \qquad &\iff \qquad n \in m, \\
    m \leq n \qquad &\iff \qquad m \in n \, \vee \, m = n, \\
    m \geq n \qquad &\iff \qquad m = n \, \vee \, n \in m.
  \end{align*}
\end{definition}

\begin{proposition}
  The following statements hold for any $\ell, m, n \in \omega$.
  \begin{enumerate}[(a)]
    \item If $\ell < m$ and $m < n$, then $\ell < n$.
    \item If $\ell < m$ and $m \leq n$, then $\ell < n$.
    \item If $\ell \leq m$ and $m < n$, then $\ell < n$.
    \item If $\ell \leq m$ and $m \leq n$, then $\ell \leq n$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Straightforward from transitivity of elements of $\omega$.
    \item Clearly $m = n$ implies $\ell < n$, and $m < n$ implies $\ell < n$ by (a).
    \item Clearly $\ell = m$ implies $\ell < n$, and $\ell < m$ implies $\ell < n$ by (a).
    \item Straightforward from (a).
    \qedhere
  \end{enumerate}
\end{proof}

\begin{proposition}
  Let $m, n \in \omega$.
  We have $m < n + 1$ if and only if $m \leq n$.
\end{proposition}
\begin{proof}
  We have $m \in \suc(n)$ if and only if $m \in n \cup \{n\}$, if and only if either $m \in n$ or $m = n$.
\end{proof}

\begin{proposition}
  The following statements hold for any $m, n \in \omega$.
  \begin{enumerate}[(a)]
    \item $0 \leq n$.
    \item If $m + 1 < n + 1$, then $m < n$.
    \item $n \not < n$.
    \item If $m < n$, then $m + 1 < n + 1$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Induction on $n$.
    Clearly $0 \leq 0$.
    If $0 \leq n$, then $0 \leq n \leq n + 1$.
    \item We have $m < m + 1 \leq n$.
    \item Induction on $n$.
    Clearly $0 \not < 0$.
    If $n \not < n$, then $n + 1 \not < n + 1$ by (b).
    \item Induction on $n$.
    Since $m \not < 0$, the inductive basis holds.
    Now assume that $m < n$ implies $m + 1 < n + 1$.
    If $m < n + 1$, then we have $m \leq n$, implying $m + 1 \leq n + 1 < (n + 1) + 1$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{theorem}[Trichotomy]
  The following statements hold for any $m, n \in \omega$.
  \begin{enumerate}[(a)]
    \item At most one of $m = n$, $m < n$ and $m > n$ holds.
    \item At least one of $m = n$, $m < n$ and $m > n$ holds.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item Neither $n = m < n$, $m < n < m$, nor $n < m = n$ holds.
    \item Induction on $n$.
    Clearly $m \geq 0$.
    If $m \leq n$, then $m < n + 1$.
    If $m > n$, then $m \geq n + 1$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{corollary}
  The relation
  \begin{equation*}
    \mathord{<}_\omega = \{(m, n) \in \omega \times \omega: m < n\}
  \end{equation*}
  is a linear ordering over $\omega$.
\end{corollary}
\begin{proof}
  Straightforward.
\end{proof}

\begin{theorem}
  The relation $<_\omega$ well-orders $\omega$.
  That is, every nonempty subset of $\omega$ admits a smallest element.
\end{theorem}
\begin{proof}
  Suppose that $S \subseteq \omega$ does not have a smallest element.
  We prove that $S = \varnothing$.
  \par First, define
  \begin{equation*}
    R = \{m \in \omega: \forall n (n \in S \to m \leq n)\},
  \end{equation*}
  which is the set of lower bounds of $S$.
  We show that $R$ is inductive.
  Clearly $0 \in R$.
  Now suppose that $m \in R$.
  If $m \in S$, then $m$ is a smallest element of $S$ since $m \leq n$ for each $n \in S$, contradition.
  Thus, $m \notin S$, implying $m + 1 \in R$.
  It follows that $R$ is inductive, i.e., $R = \omega$.
  \par Now we show that $S$ is empty.
  Suppose that $n \in S$.
  Then since $n + 1 \in \omega = R$, we have $n \geq n + 1$, contradition.
  Thus, $S = \varnothing$.
\end{proof}

\section{April 13, 2021}
\subsection{Equivalence Relations}
\begin{definition}
  Let $X$ be a set.
  A relation $E \subseteq X \times X$ is an \emph{equivalence relation} over $X$ if the following conditions hold for any $x, y, z \in X$.
  \begin{enumerate}[(i)]
    \item (Reflexivity) For any $x \in X$, we have $(x, x) \in E$.
    \item (Symmetry) For any $x, y \in X$, $(x, y) \in E$ implies $(y, x) \in E$.
    \item (Transitivity) For any $x, y, z \in X$, $(x, y) \in E$ and $(y, z) \in E$ imply $(x, z) \in E$.
  \end{enumerate}
\end{definition}

\begin{definition}
  Let $E$ be an equivalence relation over a set $X$.
  For each $x \in X$, the \emph{equivalence class} of $x$ in $X$ with respect to $E$, denoted by $[x]_E$, is defined by
  \begin{equation*}
    [x]_E = \{y \in X: (x, y) \in E\}.
  \end{equation*}
\end{definition}

\subsection{Integral Systems}
In this section, we construct an integral system $\zeta$ from the Peano system $\omega$.

\begin{definition}
  Let $Z$ be the relation over $\omega \times \omega$ such that
  for each $m, m', n, n' \in \omega$,
  \begin{equation*}
    ((m, n), (m', n')) \in Z \qquad \iff \qquad m + n' = m' + n.
  \end{equation*}
\end{definition}

\begin{proposition}
  $Z$ is an equivalence relation over $\omega \times \omega$.
\end{proposition}
\begin{proof}
  Let $m, m', m'', n, n', n''$ be arbitrary elements of $\omega$.
  Clearly $((m, n), (m, n)) \in Z$.
  If $((m, n), (m', n')) \in Z$, then we have $m' + n = m + n'$, implying $((m', n'), (m, n)) \in Z$.
  Now suppose that
  \begin{equation*}
    ((m, n), (m', n')), \quad ((m', n'), (m'', n'')) \quad \in \quad Z.
  \end{equation*}
  Then we have
  \begin{align*}
    (m' + n') + (m + n'')
    &= (m + n') + (m' + n'') \\
    &= (m' + n) + (m'' + n') \\
    &= (m' + n') + (m'' + n),
  \end{align*}
  implying $m + n'' = m'' + n$.
  Thus, $((m, n), (m'', n'')) \in Z$.
\end{proof}

\begin{definition}
  Let $\zeta = (\omega \times \omega) / Z$.
\end{definition}

\begin{proposition}
  Suppose that
  \begin{equation*}
    [(k, \ell)]_Z = [(k', \ell')]_Z \qquad \text{and} \qquad [(m, n)]_Z = [(m', n')]_Z
  \end{equation*}
  hold for some $k, k', \ell, \ell', m, m', n, n' \in \omega$.
  Then the following statements are true.
  \begin{enumerate}[(a)]
    \item $[(k + m, \ell + n)]_Z = [(k' + m', \ell' + n')]_Z$.
    \item $[(n, m)]_Z = [(n', m')]_Z$.
    \item $[(km + \ell n, kn + \ell m)]_Z = [(k'm' + \ell'n', k'n' + \ell'm')]_Z$.
    \item If $k + n < \ell + m$, then $k' + n' < \ell' + m'$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item We have
    \begin{equation*}
      (k + m) + (\ell' + n')
      = (k + \ell') + (m + n')
      = (k' + \ell) + (m' + n)
      = (k' + m') + (\ell + n).
    \end{equation*}
    \item We have $n + m' = m' + n = m + n' = n' + m$.
    \item Since
    \begin{align*}
      (km + \ell n) + (k'n + \ell'm)
      &= (k + \ell')m + (k' + \ell)n \\
      &= (k' + \ell)m + (k + \ell')n \\
      &= (k'm + \ell'n) + (kn + \ell m),
    \end{align*}
    we have
    \begin{equation*}
      [(km + \ell n, kn + \ell m)]_Z = [(k'm + \ell'n, k'n + \ell'm)]_Z.
    \end{equation*}
    Also, since
    \begin{align*}
      (k'm + \ell'n) + (k'n' + \ell'm')
      &= k'(m + n') + \ell'(m' + n) \\
      &= k'(m' + n) + \ell'(m + n') \\
      &= (k'm' + \ell'n') + (k'n + \ell'm),
    \end{align*}
    we have
    \begin{equation*}
      [(k'm + \ell'n, k'n + \ell'm)]_Z = [(k'm' + \ell'n', k'n' + \ell'm')]_Z.
    \end{equation*}
    It follows that
    \begin{equation*}
      [(km + \ell n, kn + \ell m)]_Z = [(k'm + \ell'n, k'n + \ell'm)]_Z = [(k'm' + \ell'n', k'n' + \ell'm')]_Z.
    \end{equation*}
    \item Since
    \begin{align*}
      (\ell + m) + (k' + n')
      &= (k' + \ell) + (m + n') \\
      &= (k + \ell') + (m' + n) \\
      &= (\ell' + m') + (k + n) \\
      &< (\ell' + m') + (\ell + m) \\
      &= (\ell + m) + (\ell' + m'),
    \end{align*}
    we have $k' + n' < \ell' + m'$.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{definition}
  Define
  \begin{equation*}
    0_\zeta = [(0, 0)]_Z \qquad \text{and} \qquad 1_\zeta = [(1, 0)]_Z.
  \end{equation*}
  For any $k, \ell, m, n \in \omega$, we define
  \begin{align*}
    [(k, \ell)]_Z + [(m, n)]_Z \quad &= \quad [(k + m, \ell + n)]_Z, \\
    -[(m, n)]_Z \quad &= \quad [(n, m)]_Z, \\
    [(k, \ell)]_Z \cdot [(m, n)]_Z \quad &= \quad [(km + \ell n, kn + \ell m)]_Z,
  \end{align*}
  and
  \begin{equation*}
    [(k, \ell)]_Z < [(m, n)]_Z \quad \iff \quad k + n < m + \ell.
  \end{equation*}
  Also, let
  \begin{equation*}
    \zeta^* = \{a \in \zeta: a \neq 0_\zeta\}, \qquad
    \zeta^+ = \{a \in \zeta: a > 0_\zeta\}, \qquad
    \zeta^- = \{a \in \zeta: a < 0_\zeta\}.
  \end{equation*}
\end{definition}

\begin{theorem}
  The following statements hold for any $a, b, c \in \zeta$.
  \begin{enumerate}[(a)]
    \item $a + b = b + a$.
    \item $(a + b) + c = a + (b + c)$.
    \item $0_\zeta + a = a$ and $-a + a = 0_\zeta$.
    \item $a \cdot b = b \cdot a$.
    \item $(a \cdot b) \cdot c = a \cdot (b \cdot c)$.
    \item $1_\zeta \cdot a = 1_\zeta$.
    \item $a \cdot (b + c) = a \cdot b + a \cdot c$.
    \item Exactly one of $a < b$, $a = b$ and $a > b$ holds.
    \item If $a < b$ and $b < c$, then $a < c$.
    \item If $b < c$, then $a + b < a + c$.
    \item If $a > 0_\zeta$ and $b > 0_\zeta$, then $ab > 0_\zeta$.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \leavevmode
  \begin{enumerate}[(a)]
    \item For any $k, \ell, m, n \in \omega$, we have
    \begin{equation*}
      [(k, \ell)]_Z + [(m, n)]_Z
      = [(k + m, \ell + n)]_Z
      = [(m + k, n + \ell)]_Z
      = [(m, n)]_Z + [(k, \ell)]_Z.
    \end{equation*}
    \item For any $k, \ell, m, n, p, q \in \omega$, we have
    \begin{align*}
      ([(k, \ell)]_Z + [(m, n)]_Z) + [(p, q)]_Z
      &= [(k+m, \ell+n)]_Z + [(p, q)]_Z \\
      &= [((k+m)+p, (\ell+n)+q)]_Z \\
      &= [(k+(m+p), \ell+(n+q))]_Z \\
      &= [(k, \ell)]_Z + ([(m, n)]_Z + [(p, q)]_Z).
    \end{align*}
    \item For any $m, n \in \omega$, we have
    \begin{equation*}
      [(0, 0)]_Z + [(m, n)]_Z = [(0 + m, 0 + n)]_Z = [(m, n)]_Z
    \end{equation*}
    and
    \begin{equation*}
      [(n, m)]_Z + [(m, n)]_Z = [(n + m, m + n)]_Z = [(0, 0)]_Z.
    \end{equation*}
    \item For any $k, \ell, m, n \in \omega$, we have
    \begin{equation*}
      [(k, \ell)]_Z \cdot [(m, n)]_Z
      = [(km + \ell n, kn + \ell m)]_Z
      = [(mk + n\ell, m\ell + nk)]_Z
      = [(m, n)]_Z \cdot [(k, \ell)]_Z.
    \end{equation*}
    \item For any $k, \ell, m, n, p, q \in \omega$, we have
    \begin{align*}
      ([(k, \ell)]_Z \cdot [(m, n)]_Z) \cdot [(p, q)]_Z
      &= [(km + \ell n, kn + \ell m)]_Z ] \cdot [(p, q)]_Z \\
      &= [((km + \ell n)p + (kn + \ell m)q, (km + \ell n)q + (kn + \ell m)p)]_Z \\
      &= [(kmp + knq + \ell mq + \ell np, kmq + knp + \ell mp + \ell nq)]_Z \\
      &= [(k(mp + nq) + \ell(mq + np), k(mq + np) + \ell(mp + nq))]_Z \\
      &= [(k, \ell)]_Z \cdot [(mp + nq, mq + np)]_Z \\
      &= [(k, \ell)]_Z \cdot ([(m, n)]_Z \cdot [(p, q)]_Z).
    \end{align*}
    \item For any $m, n \in \omega$, we have
    \begin{equation*}
      [(1, 0)]_Z \cdot [(m, n)]_Z = [(1m + 0n, 0m + 1n)]_Z = [(m, n)]_Z.
    \end{equation*}
    \item For any $k, \ell, m, n, p, q \in \omega$, we have
    \begin{align*}
      [(k, \ell)]_Z \cdot ([(m, n)]_Z + [(p, q)]_Z)
      &= [(k, \ell)]_Z \cdot [(m + p, n + q)]_Z \\
      &= [(k(m+p) + \ell(n+q), k(n+q) + \ell(m+p))]_Z \\
      &= [(km+kp+\ell n+\ell q, kn+kq+\ell m+\ell p)]_Z \\
      &= [(km+\ell n, kn+\ell m)]_Z + [(kp+\ell q, kq+\ell p)]_Z \\
      &= [(k, \ell)]_Z \cdot [(m, n)]_Z + [(k, \ell)]_Z \cdot [(p, q)]_Z.
    \end{align*}
    \item For any $k, \ell, m, n \in \omega$, we have
    \begin{align*}
      [(k, \ell)]_Z = [(m, n)]_Z \quad &\iff \quad k + n = m + \ell, \\
      [(k, \ell)]_Z < [(m, n)]_Z \quad &\iff \quad k + n < m + \ell, \\
      [(k, \ell)]_Z > [(m, n)]_Z \quad &\iff \quad k + n > m + \ell.
    \end{align*}
    \item Suppose that
    \begin{equation*}
      [(k, \ell)]_Z < [(m, n)]_Z \qquad \text{and} \qquad [(m, n)]_Z < [(p, q)]_Z
    \end{equation*}
    for some $k, \ell, m, n, p, q \in \omega$.
    Then we have
    \begin{align*}
      n + (k + q)
      &= q + (k + n) \\
      &< q + (m + \ell) \\
      &= \ell + (m + q) \\
      &< \ell + (p + n) \\
      &= n + (p + \ell).
    \end{align*}
    Thus, $k + q < p + \ell$, and it follows that $[(k, \ell)]_Z < [(p, q)]_Z$.
    \item Suppose that $[(m, n)]_Z < [(p, q)]_Z$ for some $m, n, p, q \in \omega$.
    We have $m + q < p + n$.
    Then for any $k, \ell \in \omega$,
    \begin{equation*}
      (k + m) + (\ell + q)
      = (k + \ell) + (m + q)
      < (k + \ell) + (p + n)
      = (k + p) + (\ell + n).
    \end{equation*}
    It follows that
    \begin{equation*}
      [(k, \ell)]_Z + [(m, n)]_Z
      = [(k + m, \ell + n)]_Z
      < [(k + p, \ell + q)]_Z
      = [(k, \ell)]_Z + [(p, q)]_Z.
    \end{equation*}
    \item Todo.
    \qedhere
  \end{enumerate}
\end{proof}

\subsection{Rational Systems}
In this section, we construct a rational system $\eta$ from the integral system $\zeta$.

\begin{definition}
  Let $R$ be the relation over $\zeta \times \zeta^*$ such that for each $a, a' \in \zeta$ and $b, b' \in \zeta^*$,
  \begin{equation*}
    ((a, b), (a', b')) \in R \qquad \iff \qquad a \cdot b' = a' \cdot b.
  \end{equation*}
\end{definition}

\begin{proposition}
  $R$ is an equivalence relation over $\zeta \times \zeta^*$.
\end{proposition}

\begin{definition}
  Let $\eta = (\zeta \times \zeta^*) / R$.
\end{definition}

\begin{definition}
  Define
  \begin{equation*}
    0_\eta = [(0_\zeta, 1_\zeta)]_R \qquad \text{and} \qquad 1_\eta = [(1_\zeta, 1_\zeta)]_R.
  \end{equation*}
  For any $a, c \in \zeta$ and $b, d \in \zeta^*$, we define
  \begin{align*}
    [(a, b)]_R + [(c, d)]_R \quad &= \quad [(ad + bc, bd)]_R, \\
    -[(a, b)]_R \quad &= \quad [(-a, b)]_R, \\
    [(a, b)]_R \cdot [(c, d)]_R \quad &= \quad [(ac, bd)]_R,
  \end{align*}
  and
  \begin{equation*}
    [(a, b)]_Z < [(c, d)]_Z \quad \iff \quad ad \cdot bd < bc \cdot bd.
  \end{equation*}
  If $a \in \zeta^*$, then we define
  \begin{equation*}
    \bigl([(a, b)]_R\bigr)^{-1} \quad = \quad [(b, a)]_R.
  \end{equation*}
  Also, let
  \begin{equation*}
    \eta^* = \{q \in \eta: q \neq 0_\eta\}, \qquad
    \eta^+ = \{q \in \eta: q > 0_\eta\}, \qquad
    \eta^- = \{q \in \eta: q < 0_\eta\}.
  \end{equation*}
\end{definition}

\section{April 20, 2021}
\subsection{Real Systems}
\begin{definition}
  A \emph{Dedekind cut} is set $X \subseteq \eta$ satisfying the following properties.
  \begin{enumerate}[(i)]
    \item $X \neq \varnothing$ and $X \neq \eta$.
    \item For any $p, q \in \eta$, if $q \in X$ and $p < q$, then $p \in X$.
    \item $X$ does not admit a greatest element.
  \end{enumerate}
  Let $\lambda$ denote the set of all Dedekind cuts.
\end{definition}

\begin{definition}
  Define
  \begin{equation*}
    0_\lambda = \{q \in \eta: q < 0_\eta\}
    \qquad \text{and} \qquad
    1_\lambda = \{q \in \eta: q < 1_\eta\}.
  \end{equation*}
  For any $X, Y \in \lambda$, we define
  \begin{align*}
    X + Y \quad &= \quad \{r \in \eta: \exists p \exists q (p \in X \wedge q \in Y \wedge p + q = r)\}, \\
    -X \quad &= \quad \{p \in \eta: \exists q (q \in \eta \setminus X \wedge p + q < 0_\eta)\}
  \end{align*}
  and
  \begin{equation*}
    X < Y \quad \iff \quad X \subsetneq Y.
  \end{equation*}
  Also, let
  \begin{equation*}
    \lambda^* = \{q \in \lambda: q \neq 0_\lambda\}, \qquad
    \lambda^+ = \{q \in \lambda: 0_\lambda < q\}, \qquad
    \lambda^- = \{q \in \lambda: q < 0_\lambda\}.
  \end{equation*}
\end{definition}

\begin{definition}
  Let
  \begin{equation*}
    X \odot Y \quad = \quad \eta \setminus \{r \in \eta: \exists p \exists q (p \in \eta \setminus X \wedge q \in \eta \setminus Y \wedge p \cdot q = r)\}
  \end{equation*}
  for any $X, Y \in \{0_\lambda\} \cup \lambda^+$.
\end{definition}

\begin{definition}
  For any $X \in \lambda$, let $X^+ = \max(\{X, 0\})$ and $X^- = \max(\{-X, 0\})$.
\end{definition}

\begin{definition}
  Let
  \begin{equation*}
    X \cdot Y \quad = \quad (X^+ \odot Y^+ + X^- \odot Y^-) + (-(X^+ \odot Y^- + X^- \odot Y^+))
  \end{equation*}
  for any $X, Y \in \lambda$.
\end{definition}

\begin{definition}
  Let
  \begin{equation*}
    X^{-1} \quad = \quad \{p \in \eta: \exists q (q \in \eta \setminus X \wedge p \cdot q < 1_\eta)\}
  \end{equation*}
  for any $X \in \lambda^*$.
\end{definition}

\end{document}
